{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98d2e1dc-2b5f-4de3-8a8f-64a285a5939a",
   "metadata": {},
   "source": [
    "# GraphRAG with GraphDB and LangChain\n",
    "This is the notebook that accompanies my blogpost about doing GraphRAG with GraphDB and LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49e456fe-7513-425b-b9d3-14727f9db981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from typing import Dict, Any, List\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.graphs import OntotextGraphDBGraph\n",
    "from langchain_community.chains.graph_qa.prompts import GRAPHDB_QA_TEMPLATE\n",
    "from elasticsearch import Elasticsearch\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6800ab70-1b77-4fa4-aebe-b8e4ae9db4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint for GraphDB\n",
    "graphdb_endpoint = \"http://localhost:7200/repositories/msft-graphrag-300\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de01ee46-c198-4129-bfc4-7a35c44064ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_username = 'elastic'\n",
    "es_password = ''  # put your password here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c1213a-fbb9-4307-8f6f-9076df044d45",
   "metadata": {},
   "source": [
    "## Setup the question\n",
    "The question we will ask will be:\n",
    "```\n",
    "What is the relationship between Bob Cratchit and Belinda Cratchit?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eca9f10-9f73-4dbe-af34-a1855e2d95f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_text = \"What is the relationship between Bob Cratchit and Belinda Cratchit?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c518e3c-4d7f-4843-bf86-1e3a528d73c4",
   "metadata": {},
   "source": [
    "## Convert the question text\n",
    "First step is to convert the question into an embedding vector. To do this we will use our local LM Studio instance and call the embedding OpenAI endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aa78b3f-1f42-4440-aefc-ccf433fb5ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str, client: Any, model: str=\"CompendiumLabs/bge-large-en-v1.5-gguf\"):\n",
    "    \"\"\"Convert the text into an embedding vector using the model provided\n",
    "\n",
    "    :param text: text to be converted to and embedding vector\n",
    "    :param client: OpenAI client\n",
    "    :param model: name of the model to use for encoding\n",
    "    \"\"\"\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50255fe7-6c74-4c3f-9605-5c6a592abd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3babb3c-9cbb-4bfa-b26a-3ec27d3db107",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector = get_embedding(question_text, client=client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b8a1f9-54a9-46fa-a635-32547825fc2c",
   "metadata": {},
   "source": [
    "Set the limits for our searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b0ea94e-994c-4c07-8351-6ad8ad2fa9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_chunks = 3\n",
    "top_communities = 3\n",
    "top_outside_relationships = 10\n",
    "top_inside_relationships = 10\n",
    "top_entities = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f678b90d-359d-4e6d-a5ea-2ab5d17754cd",
   "metadata": {},
   "source": [
    "## Find nearest Entities\n",
    "Now we need to use our Elasticsearch index to do a k-nearest neighbour search for our **embedding_vector** to find the 10 nearest `Entity` instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89699af6-e6ef-4c06-9b9f-d86764754382",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"entity_graph_index\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b199dd6d-3d6b-4122-a1b4-92a115424d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(\"http://localhost:9200\", \n",
    "                   basic_auth=(es_username, es_password), \n",
    "                   verify_certs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e33f7d63-2f06-4192-859d-0fa97dfeb376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dde131ab575d44dbb55289a6972be18f',\n",
       " '68105770b523412388424d984e711917',\n",
       " '40e4ef7dbc98473ba311bd837859a62a',\n",
       " '254770028d7a4fa9877da4ba0ad5ad21',\n",
       " 'da1684437ab04f23adac28ff70bd8429',\n",
       " 'd91a266f766b4737a06b0fda588ba40b',\n",
       " 'bc0e3f075a4c4ebbb7c7b152b65a5625',\n",
       " '23becf8c6fca4f47a53ec4883d4bf63f',\n",
       " '496f17c2f74244c681db1b23c7a39c0c',\n",
       " '3d0dcbc8971b415ea18065edc4d8c8ef']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = {\n",
    "    \"field\" : \"description_embedding\" ,\n",
    "    \"query_vector\" : embedding_vector,\n",
    "    \"k\" : top_entities,\n",
    "    \"num_candidates\" : 100 ,\n",
    "}\n",
    "res = es.search(index=index_name, knn=query, source=[\"id\"])\n",
    "search_results = res[\"hits\"][\"hits\"]\n",
    "# convert our results into a list of Entities\n",
    "# This list will be ordered by match score descending (i.e the more likely matches will be at the beginning)\n",
    "entity_list = [x['_id'] for x in search_results]\n",
    "entity_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2944205d-cadc-4634-affb-8683aead0fe2",
   "metadata": {},
   "source": [
    "## Using OntotextGraphDBGraph\n",
    "We'll use the `OntotextGraphDBGraph` class in LangChain to define our interface to the GraphDB instance. One of the things that it needs is an Ontology, which is included in this repository: [msft-graphrag.owl](../data/msft-graphrag.owl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bbee958-bf02-4f56-83b1-bcc07fea162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology_path = \"D:/Data/RDF/msft-graphrag.owl\"\n",
    "graph = OntotextGraphDBGraph(\n",
    "    query_endpoint=graphdb_endpoint,\n",
    "    local_file=ontology_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e1e95e-0e87-4b23-a577-14b331073c9f",
   "metadata": {},
   "source": [
    "### Create an Entity Filter\n",
    "Create an `Entity` filter in SPARQL that we'll use to limit our searches later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ad0a808-a106-4017-99a9-09ec9846630d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FILTER(?id = \"dde131ab575d44dbb55289a6972be18f\"  || ?id = \"68105770b523412388424d984e711917\"  || ?id = \"40e4ef7dbc98473ba311bd837859a62a\"  || ?id = \"254770028d7a4fa9877da4ba0ad5ad21\"  || ?id = \"da1684437ab04f23adac28ff70bd8429\"  || ?id = \"d91a266f766b4737a06b0fda588ba40b\"  || ?id = \"bc0e3f075a4c4ebbb7c7b152b65a5625\"  || ?id = \"23becf8c6fca4f47a53ec4883d4bf63f\"  || ?id = \"496f17c2f74244c681db1b23c7a39c0c\"  || ?id = \"3d0dcbc8971b415ea18065edc4d8c8ef\" )'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_id_filter = \"\"\n",
    "first = True\n",
    "for entity_id in entity_list:\n",
    "    if first:\n",
    "        entity_id_filter += \"FILTER(\"\n",
    "    else:\n",
    "        entity_id_filter += \" || \"\n",
    "    entity_id_filter += f'?id = \"{entity_id}\" '\n",
    "    first = False\n",
    "entity_id_filter += \")\"\n",
    "entity_id_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8adb5ce-f3e9-4b6b-9cb3-eb147aba6f4c",
   "metadata": {},
   "source": [
    "### Create our Main SPARQL query\n",
    "Create our main SPARQL query using our **entity_id_filter** and the information in our Knowledge Graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75f4be42-9007-4f12-8e87-18b1fef1c591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiple(entity_id_filter: str, \n",
    "                 limit_chunks: int = 3, \n",
    "                 limit_communities: int = 3,\n",
    "                 limit_inside_relationships: int = 10,\n",
    "                 limit_outside_relationships: int = 10):\n",
    "    \"\"\"Combine multiple SPARQL queries into one\n",
    "\n",
    "    :param entity_id_filter: SPARQL FILTER text for Entity IDs\n",
    "    :param limit_chunks: maximum number of Chunk records to fetch\n",
    "    :param limit_communities: maximum number of Community records to fetch\n",
    "    :param limit_inside_relationships: maximum number of inside related_to records to fetch\n",
    "    :param limit_outside_relationships: maximum number of outside related_to records to fetch\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "PREFIX gr: <http://ormynet.com/ns/msft-graphrag#>\n",
    "\n",
    "SELECT * WHERE\n",
    "{ \n",
    "  {\n",
    "    #-- Entities -->\n",
    "    SELECT ?description\n",
    "    WHERE\n",
    "    {\n",
    "        ?entity_uri a gr:Entity;\n",
    "        gr:id ?id;\n",
    "        gr:description ?entity_desc .\n",
    "        BIND(REPLACE(?entity_desc, \"\\\\r\\\\n\", \" \", \"i\") AS ?description)\n",
    "    \"\"\"\n",
    "    query += entity_id_filter\n",
    "    query += \"\"\"\n",
    "    }\n",
    "  }\n",
    "  UNION\n",
    "  {\n",
    "    #-- Chunks -->\n",
    "    SELECT \n",
    "    ?chunkText \n",
    "    (COUNT(?entity_uri) AS ?freq)\n",
    "    WHERE {\n",
    "        ?chunk_uri gr:has_entity ?entity_uri;\n",
    "        gr:text ?chunk_text .\n",
    "        ?entity_uri a gr:Entity;\n",
    "            gr:id ?id .\n",
    "    \"\"\"\n",
    "    query += entity_id_filter\n",
    "    query += \"\"\"\n",
    "        BIND(REPLACE(?chunk_text, \"\\\\r\\\\n\", \" \") as ?chunkText)\n",
    "    }\n",
    "    GROUP BY ?chunk_uri ?chunkText\n",
    "    ORDER BY DESC(?freq)\n",
    "    \"\"\"\n",
    "    query += f\" LIMIT {limit_chunks} \"\n",
    "    query += \"\"\"\n",
    "  }\n",
    "  UNION\n",
    "  {\n",
    "    #-- Communities -->\n",
    "    SELECT ?summary\n",
    "    WHERE\n",
    "    {\n",
    "        ?community_uri a gr:Community;\n",
    "          gr:rank ?rank;\n",
    "          gr:weight ?weight;\n",
    "          gr:summary ?community_summary .\n",
    "        BIND(REPLACE(?community_summary, \"\\\\r\\\\n\", \" \", \"i\") AS ?summary)\n",
    "        ?entity_uri gr:in_community ?community_uri;\n",
    "            gr:id ?id .\n",
    "    \"\"\"\n",
    "    query += entity_id_filter\n",
    "    query += \"\"\"\n",
    "    }\n",
    "    GROUP BY ?rank ?weight ?community_uri ?summary\n",
    "    ORDER BY DESC(?rank) DESC(?weight)\n",
    "    \"\"\"\n",
    "    query += f\" LIMIT {limit_communities} \"\n",
    "    query += \"\"\"\n",
    "  }\n",
    "  UNION\n",
    "  {\n",
    "    #-- Outside Relationships -->\n",
    "    SELECT ?description\n",
    "    WHERE {\n",
    "        ?related_to_uri a gr:related_to;\n",
    "            gr:id ?related_id;\n",
    "            gr:rank ?rank;\n",
    "            gr:description ?desc;\n",
    "            gr:weight ?weight .\n",
    "        BIND(REPLACE(?desc, \"\\\\r\\\\n\", \"\") as ?description)\n",
    "        ?entity_from_uri ?related_to_uri ?entity_to_uri .\n",
    "        ?entity_from_uri gr:id ?entity_from_id .\n",
    "        ?entity_to_uri gr:id ?id .\n",
    "    \"\"\"\n",
    "    query += entity_id_filter\n",
    "    query += \"\"\"\n",
    "    }\n",
    "    ORDER BY DESC(?rank) DESC(?weight)\n",
    "    \"\"\"\n",
    "    query += f\" LIMIT {limit_inside_relationships} \"  \n",
    "    query += \"\"\"\n",
    "  }\n",
    "  UNION\n",
    "  {\n",
    "    #-- Inside Relationships -->\n",
    "        SELECT ?description\n",
    "        WHERE {\n",
    "            ?related_to_uri a gr:related_to;\n",
    "                gr:id ?related_id;\n",
    "                gr:rank ?rank;\n",
    "                gr:description ?desc;\n",
    "                gr:weight ?weight .\n",
    "            BIND(REPLACE(?desc, \"\\\\r\\\\n\", \"\") as ?description)\n",
    "            ?entity_from_uri ?related_to_uri ?entity_to_uri .\n",
    "            ?entity_from_uri gr:id ?id .\n",
    "            ?entity_to_uri gr:id ?entity_to_id .\n",
    "    \"\"\"\n",
    "    query += entity_id_filter\n",
    "    query += \"\"\"\n",
    "    }\n",
    "    ORDER BY DESC(?rank) DESC(?weight)\n",
    "    \"\"\"\n",
    "    query += f\" LIMIT {limit_outside_relationships} \"  \n",
    "    query += \"\"\"\n",
    "  }\n",
    "}\n",
    "    \"\"\"\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "840de781-4503-4930-accd-bf65f23623a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sparql = get_multiple(entity_id_filter, \n",
    "                            top_chunks, \n",
    "                            top_communities, \n",
    "                            top_inside_relationships, \n",
    "                            top_outside_relationships)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf0ae81-0dd3-4d4a-a43c-9cf53753b66b",
   "metadata": {},
   "source": [
    "### Use the GraphDB interface to do the SPARQL query\n",
    "We will now use our LangChain GraphDB graph to perform the SPARQL query. What is returned is a list of RDF triples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63f8b75f-f153-4886-9743-ffd3b60c5b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_results = graph.query(query_sparql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6d2ac2-5c26-43d3-983c-ac03ffae7aab",
   "metadata": {},
   "source": [
    "### Inject the RDF Triples into the Prompt\n",
    "Within LangChain there is a prompt template that we can use that can cope with RDF triples. It's called `GRAPHDB_QA_TEMPLATE`. This is what it says:\n",
    "\n",
    "```\n",
    "Task: Generate a natural language response from the results of a SPARQL query.\n",
    "You are an assistant that creates well-written and human understandable answers.\n",
    "The information part contains the information provided, which you can use to construct an answer.\n",
    "The information provided is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\n",
    "Make your response sound like the information is coming from an AI assistant, but don't add any information.\n",
    "Don't use internal knowledge to answer the question, just say you don't know if no information is available.\n",
    "Information:\n",
    "{context}\n",
    "\n",
    "Question: {prompt}\n",
    "Helpful Answer:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cb147b9-f1b6-4ef1-b227-f8528e8be5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    api_key=\"lm-server\",\n",
    "    base_url=\"http://localhost:1234/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0466ebe-b2fb-4c23-ba5d-e4fd6b06fd87",
   "metadata": {},
   "source": [
    "Create our PromptTemplate using the `GRAPHDB_QA_TEMPLATE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30e3d1c7-9e3b-472a-8781-f53e777b8b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"prompt\"], \n",
    "    template=GRAPHDB_QA_TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492fca57-8b0a-46ac-9915-ad2682ca5c3a",
   "metadata": {},
   "source": [
    "Create our LangChain chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "517fc97c-4648-48a3-9e92-2c4ccf1ed776",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = qa_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a446e9a-083c-4c7e-814e-7879953a92df",
   "metadata": {},
   "source": [
    "Now we can use the chain to do ask our question and get our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b1e2d12-aefc-4a54-afaf-20d8d711ffc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the information provided, Belinda Cratchit is a daughter of Bob Cratchit. Additionally, it is mentioned that Mrs. Cratchit and Miss Belinda collaborate on food preparation for the family gathering, suggesting a close relationship between them as part of the same family unit.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.invoke(\n",
    "    {\n",
    "        \"prompt\": {'query': question_text}, \n",
    "        \"context\": query_results\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b8e52d-9c71-494b-8529-2b8fc7561651",
   "metadata": {},
   "source": [
    "## Prompt with no context\n",
    "To show again, how much better this answer is than if we had simply asked the question to ChatGPT, here is what happens when we do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23a63c8e-1e94-4dd2-b973-c3692c7aba9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In Charles Dickens\\' novel \"A Christmas Carol\", there is no character named Belinda Cratchit. However, I believe you may be thinking of Mrs. Cratchit, who is the wife of Bob Cratchit.\\n\\nMrs. Cratchit (also known as Emily) is a kind and hardworking woman who manages to keep her family together despite their poverty. She is often seen helping her husband with his work and taking care of their children.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_no_context = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that answers questions about a book.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "simple_chain = prompt_no_context | llm | StrOutputParser()\n",
    "simple_chain.invoke(\n",
    "    {\n",
    "        \"input\": question_text,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f19e62d-06fd-4ef6-8084-58d25d9400d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
